"""
LangChain ê¸°ë°˜ GPT ì‘ë‹µ ìƒì„±ê¸° (Farmì±—ìš©)
ì‚¬ìš©ìê°€ ì‰½ê²Œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ êµì²´í•˜ê±°ë‚˜ ìˆ˜ì •í•  ìˆ˜ ìˆë„ë¡ êµ¬ì¡°í™”í•¨
"""

from langchain.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import RunnablePassthrough

def build_response_chain(prompt_template: str, model_name: str = "gpt-4o", temperature: float = 0.3):
    """
    LangChain RunnableChain êµ¬ì„±

    Args:
        prompt_template (str): ì‚¬ìš©ì ì§€ì • í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        model_name (str): ì‚¬ìš©í•  OpenAI ëª¨ë¸ ì´ë¦„
        temperature (float): ìƒì„± ì˜¨ë„

    Returns:
        RunnableChain: ì‹¤í–‰ ê°€ëŠ¥í•œ ì²´ì¸
    """
    prompt = ChatPromptTemplate.from_template(prompt_template)
    model = ChatOpenAI(model=model_name, temperature=temperature)
    parser = StrOutputParser()

    chain = (
        {"question": RunnablePassthrough(), "data": RunnablePassthrough()} |
        prompt |
        model |
        parser
    )
    return chain

# ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ì‚¬ìš©ìê°€ êµì²´ ê°€ëŠ¥)
FARMCHAT_PROMPT_TEMPLATE = """
ë„ˆëŠ” ì‘ë¬¼ ìƒìœ¡ ë° í™˜ê²½ì— ëŒ€í•œ ì „ë¬¸ AI ìƒë‹´ì‚¬ì•¼. ì•„ë˜ ì •ë³´ë¥¼ ì°¸ê³ í•´ ì‚¬ìš©ì ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì¤˜.

[ì§ˆë¬¸]
{question}

[í™˜ê²½ ë°ì´í„°]
{data}

[ë‹µë³€ ì‘ì„± ì¡°ê±´]
- í•œêµ­ì–´ë¡œ ë‹µë³€í•  ê²ƒ
- ìˆ˜ì¹˜ë¥¼ ì„¤ëª…í•˜ê³  ê¸°ì¤€ì¹˜ì™€ ë¹„êµí•´ì¤„ ê²ƒ
- í•„ìš”í•œ ê²½ìš° ì‘ë¬¼ ì¬ë°° íŒì„ ì œì•ˆí•  ê²ƒ
- ë†ë¯¼ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ë§í•´ì¤„ ê²ƒ

[ì¶œë ¥ í˜•ì‹]
ğŸ“Œ ìš”ì•½
- [í•œ ì¤„ ìš”ì•½]

ğŸŒ± ì„¸ë¶€ ì„¤ëª…
- [ì§€í‘œë³„ ì„¤ëª… ë° ì˜í–¥]

ğŸ“‹ ë°ì´í„° ì¶œì²˜
- [API ì´ë¦„ ë˜ëŠ” ì œê³µê¸°ê´€]
"""

# ì˜ˆì‹œ ì‚¬ìš©
# chain = build_response_chain(FARMCHAT_PROMPT_TEMPLATE)
# result = chain.invoke({"question": "ìš°ë¦¬ ë°­ í† ì–‘ ì‚°ë„ ì–´ë•Œ?", "data": "{pH: 6.4, EC: 0.5}"})
# print(result)
